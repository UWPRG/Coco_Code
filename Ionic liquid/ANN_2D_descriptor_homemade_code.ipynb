{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from descriptor files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "X = np.genfromtxt('../datasets/Selective_descriptors_X')\n",
    "Y = np.genfromtxt('../datasets/Selective_descriptors_Y').reshape((X.shape[0],1))\n",
    "Y_error = np.genfromtxt('../datasets/Selective_descriptors_error')\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train,X_test,Y_train,Y_test,e_train,e_test = train_test_split(X,Y,Y_error,test_size=0.10,random_state=1010)\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "d = X_train.shape[1]\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(Y_train.shape,Y_test.shape)\n",
    "print(e_train.shape,e_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize hyper parameters for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing weight for first layer(w1) and second\n",
    "# Parameters\n",
    "hdnode = 100\n",
    "w1 = np.random.normal(0,0.001,d*hdnode).reshape((d,hdnode))\n",
    "d1 = np.zeros((d,hdnode))\n",
    "w2 = np.random.normal(0,0.001,hdnode).reshape((hdnode,1))\n",
    "d2 = np.zeros(hdnode)\n",
    "h  = np.zeros(hdnode)\n",
    "              \n",
    "mb = 100 #minibatch size\n",
    "m = int(n_train/mb)\n",
    "batch = np.arange(m)\n",
    "lr = 0.00020# learning rate\n",
    "EP =20000# maximum epoch \n",
    "y = np.zeros((mb,1))\n",
    "yh = np.zeros((n_train,1))\n",
    "yh2 = np.zeros((n_test,1))\n",
    "\n",
    "L_train= np.zeros(EP+1)\n",
    "L_test = np.zeros(EP+1)\n",
    "\n",
    "L01_train = np.zeros((EP+1))\n",
    "L01_test = np.zeros((EP+1))\n",
    "\n",
    "#relu\n",
    "\"\"\"def g(A):\n",
    "    return (np.maximum(A,0))\n",
    "\n",
    "def gd(A):\n",
    "    return (np.minimum(np.maximum(A,0),1))\"\"\"\n",
    "#tanh\n",
    "def g(A):\n",
    "    return (np.tanh(A))\n",
    "\n",
    "def gd(A):\n",
    "    return (1-np.square(np.tanh(A)))\n",
    "ep = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "## Change EP to change the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning stuffff....\n",
    "EP = 20000\n",
    "while ep < EP:\n",
    "    ep += 1\n",
    "\n",
    "    yh = g(X_train.dot(w1)).dot(w2)\n",
    "    yh2 = g(X_test.dot(w1)).dot(w2)\n",
    "        \n",
    "    L_train[ep] = LA.norm(yh-Y_train)/n_train\n",
    "    L_test[ep]  = LA.norm(yh2-Y_test)/n_test\n",
    "    \n",
    "    #print(ep,L_train[ep],L_test[ep])\n",
    "        \n",
    "    np.random.shuffle(batch)\n",
    "    for i in range(m):\n",
    "        st = batch[i]*mb\n",
    "        ed = (batch[i]+1)*mb\n",
    "        \n",
    "        h  = g(X_train[st:ed].dot(w1))\n",
    "        y = h.dot(w2)\n",
    "\n",
    "        d2 = h.T.dot(Y_train[st:ed]-y)\n",
    "        d1 = X_train[st:ed].T.dot(np.multiply((Y_train[st:ed]-y).dot(w2.T),gd(X_train[st:ed].dot(w1))))\n",
    "        \n",
    "        w2 += lr*d2\n",
    "        w1 += lr*d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "np.savetxt(\"w1_{}.txt\".format(EP),w1)\n",
    "np.savetxt(\"w2_{}.txt\".format(EP),w2)\n",
    "np.savetxt(\"L_train.txt\",L_train)\n",
    "np.savetxt(\"L_test.txt\",L_test)\n",
    "np.savetxt(\"prediction_train.txt\",yh)\n",
    "np.savetxt(\"prediction_test.txt\",yh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot experiment vs prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "yh = np.genfromtxt(\"prediction_train.txt\").reshape((n_train,1))\n",
    "yh2 = np.genfromtxt(\"prediction_test.txt\").reshape((n_test,1))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(Y_train,yh,s=4,color='blue')\n",
    "plt.title('MLP Regressor Prediction on Training Data',fontsize =25)\n",
    "plt.plot(np.linspace(0,12,1000),np.linspace(0,12,1000),color='black')\n",
    "plt.xlim((0,12))\n",
    "plt.ylim((0,12))\n",
    "plt.xlabel(\"Experiment($S*m^2/mol$)\",fontsize =20)\n",
    "plt.ylabel(\"Prediction($S*m^2/mol$)\",fontsize =20)\n",
    "plt.tick_params(axis='both', which='major',labelsize =15)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(Y_test,yh2,s=10,color='blue')\n",
    "plt.title('MLP Regressor Prediction on Test Data',fontsize=25)\n",
    "plt.xlim((0,12))\n",
    "plt.ylim((0,12))\n",
    "plt.xlabel(\"Experiment($S*m^2/mol$)\",fontsize =20)\n",
    "plt.ylabel(\"Prediction($S*m^2/mol$)\",fontsize =20)\n",
    "plt.plot(np.linspace(0,12,1000),np.linspace(0,12,1000),color='black')\n",
    "plt.tight_layout\n",
    "plt.tick_params(axis='both', which='major',labelsize =15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot experiments, prediciton and error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,16))\n",
    "ax = fig.add_subplot(111)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "result = pd.DataFrame(columns=['Experiment','Prediction','error'])\n",
    "result.Experiment = Y_train.reshape(n_train)\n",
    "result.Prediction = yh.reshape((n_train,1))\n",
    "result.error = e_train\n",
    "result = result.sort(['Experiment','Prediction'],ascending=[1,1])\n",
    "size = 2\n",
    "\n",
    "ax1.set_xlim((0,2300))\n",
    "ax1.set_ylim((-1,13))\n",
    "ax1.scatter(np.arange(X_train.shape[0]),result.Experiment,color=\"blue\",s=size,label='Experiment')\n",
    "ax1.scatter(np.arange(X_train.shape[0]),result.Prediction,color=\"red\",s=size,label='Prediction')\n",
    "ax1.scatter(np.arange(X_train.shape[0]),result.Experiment+result.error,color=\"green\",s=size,label='Experiment Error')\n",
    "ax1.scatter(np.arange(X_train.shape[0]),result.Experiment-result.error,color=\"green\",s=size)\n",
    "ax1.set_title('MLP Regressor Prediction on Training Data',fontsize=25)\n",
    "ax1.legend(loc='upper left',fontsize=20)\n",
    "ax1.tick_params(axis='both', which='major',labelsize =15)\n",
    "\n",
    "result = pd.DataFrame(columns=['Experiment','Prediction','error'])\n",
    "result.Experiment = Y_test.reshape(n_test)\n",
    "result.Prediction = yh2\n",
    "result.error = e_test\n",
    "result = result.sort(['Experiment','Prediction'],ascending=[1,1])\n",
    "\n",
    "size = 8\n",
    "ax2.set_xlim((0,260))\n",
    "ax2.set_ylim((-1,13))\n",
    "ax2.scatter(np.arange(X_test.shape[0]),result.Experiment,color=\"blue\",s=size,label='Experiment')\n",
    "ax2.scatter(np.arange(X_test.shape[0]),result.Prediction,color=\"red\",s=size,label='Prediction')\n",
    "ax2.scatter(np.arange(X_test.shape[0]),result.Experiment+result.error,color=\"green\",s=size,label='Experiment Error')\n",
    "ax2.scatter(np.arange(X_test.shape[0]),result.Experiment-result.error,color=\"green\",s=size)\n",
    "ax2.set_title('MLP Regressor Prediction on Test Data',fontsize=25)\n",
    "ax2.legend(loc='upper left',fontsize=20)\n",
    "ax2.tick_params(axis='both', which='major',labelsize =15)\n",
    "\n",
    "ax.set_xlabel('Data points',fontsize=20)\n",
    "ax.set_ylabel('Conductivity($S*m^2/mol$)',fontsize=20)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the error change in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim((0,ep))\n",
    "plt.ylim((0,0.06))\n",
    "plt.plot(np.linspace(1,ep,ep),L_train[:ep],c=\"orange\",label='Train error')\n",
    "plt.plot(np.linspace(1,ep,ep),L_test[:ep],c=\"blue\",label='Test error')\n",
    "plt.title(\"Mean Square Error of MLP Regressor\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Square Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train = np.genfromtxt(\"L_train.txt\")\n",
    "L_test = np.genfromtxt(\"L_test.txt\")\n",
    "ep = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot relative error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Relative error percent of MLP Regressor\")\n",
    "plt.scatter(Y_test,(yh2-Y_test)/Y_test,c='blue',s=2,alpha=0.5)\n",
    "plt.xlabel(\"Experiment Valuse of Electric Conductivity\")\n",
    "plt.ylabel(\"Relative error%\")\n",
    "#plt.ylim((-200,200))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
